# Copyright 2015 Open vStorage NV
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import simplejson
import subprocess
import json
import os

import uuid
import tempfile

from volumedriver.base import auxiliary
from volumedriver.base import env

from volumedriver.toolcut import ToolCut
# from volumedriver.toolcut import backend


logger = env.getSublogger(__name__)

LOGGER_NAME = "volumedriver_backup"
BACKUP_BINARY = "backup_volumedriver"
RESTORE_BINARY = "restore_volumedriver"

CONFIG_NAME = "backupRestore.cfg"
LOG_CONFIG_NAME = "backupRestoreLogging"

PROGRESS_INFO_NAME = "BackupInfo.json"

configTemplateFile = os.path.join(env.cfgDir, "backupConfigTemplate.json")


class PointInTimeException(Exception):

    def __init__(self,
                 value):
        Exception.__init__(self)
        self.value = value

    def __str__(self):
        return repr(self.value)


def testConfiguration():
    getConfigTemplate()


def getConfigTemplate():
    if not os.path.exists(configTemplateFile):
        raise Exception("configTemplate does not exist: %s" %
                        configTemplateFile)
    with open(configTemplateFile) as f:
        return json.load(f)


def removeProgressInfo(target):
    ''' Removes progressinfo from a target generated by a previous backup job.

             target : BackendWithNamespace

        Typical workflow for monitoring a backup job:
             1) removeProgressInfo(target)
             2) start backup(source, target) process
             3) regularly call getProgressInfo(target). This might return None initially.

        Step 1) prevents step 3) from returning info from a previous backup job.
    '''
    if target.exists(PROGRESS_INFO_NAME):
        target.deleteObject(PROGRESS_INFO_NAME)


def getProgressInfo(target):
    ''' Get progress information about a running or finished backup job.
             target : BackendWithNamespace
             returns, either None or a python dict (see further)

        If the target does not exist or is inaccessible, the method throws.

        The backup process regularly writes a progressreport as an object in it's target namespace. This method
        retrieves this object and if it exists returns it as a python dictionary.

        As the progress info is directly retrieved from the target and not through the backup process, this method might return
        None initially even if the backup job is already started. Once a dict has been returned, however, successive
        getProgressInfo calls are guaranteed to return dicts as well. Also, a successful backup job always leaves a report
        in the end, even if the backup was very short.

        The method does not need to be called on the same node where the backup process is running.
        Before starting a backup job, removeProgressInfo should be called once on the target to remove
        info that might be left from a previous backup job.

        The method returns either None or a dictionary with at least these entries:
           - "start_date" : string, start time of the backup job in UTC and formatted as "YYYY-mmm-DD HH:MM:SS"
           - "update_date": string, last time the progressinfo was updated in UTC and formatted as "YYYY-mmm-DD HH:MM:SS"
           - "report_interval_in_seconds": integer (>=0), period between two successive updates of this progressreport (seconds)
           - "runtime_in_seconds": integer (>=0) or None, how long the backup process has been running (seconds) or None if a time shift on the host
                during the backup process does not allow to give a reliable number
           - "total_size" : integer (>=0), total amount of data that needs to be examined (bytes)
           - "seen" : integer (>=0), amount of data examined (bytes)
           - "kept" : integer (>=0), amount of data examined and scheduled for transfer or already transferred (bytes)
           - "sent_to_backend" : integer (>=0),  amount of data transferred (bytes)
           - "pending" : integer (>=0), estimate of the amount of data still to be transferred (bytes)
           - "status" : string, either "finished" or "running"

        Assuming "info" is a dictionary returned by getProgressInfo(...), we have the following properties:
           - info["total_size"] remains constant during the course of a backup job
           - info["sent_to_backend"] <= info["kept"] <= info["seen"] <= info["total_size"] at all times

        When a backup is finished, we have
            info["status"] == "finished"
            info["seen"] == info["total_size"]
            info["sent_to_backend"] == info["kept"]
            info["pending"] == 0

        Example of how to create a progress indicator out of these numbers.
        - sent_to_backend/(sent_to_backend + pending)
            start:  0/total_size
            finish: sent_to_backend/sent_to_backend

            The expression (sent_to_backend + pending) is an upper bound estimate for the total amount of data
            that will have to be transferred during this backup job.
            This upper bound estimate decreases over time as we get more information about overwrites.
    '''
    runtime_in_seconds = "runtime_in_seconds"
    if target.exists(PROGRESS_INFO_NAME):
        s = str()
        try:
            s = target.getObjectAsString(PROGRESS_INFO_NAME)
        except RuntimeError as e:
            logger.error(str(e))
            return None
        dct = simplejson.loads(s)

        # in python 2.6, simplejson seems to return unicode instead of plain
        # str
        for k in ["start_date",
                  "update_date",
                  "status"]:
            dct[k] = dct[k].encode("utf-8")

        for k in ["total_size",
                  "still_to_be_examined",
                  "seen",
                  "sent_to_backend",
                  "pending",
                  "report_interval_in_seconds",
                  "kept"]:
            dct[k] = int(dct[k])

        if dct[runtime_in_seconds] == "unavailable":
            dct[runtime_in_seconds] = None
        else:
            dct[runtime_in_seconds] = int(dct[runtime_in_seconds])

        if dct[runtime_in_seconds] < 0:
            dct[runtime_in_seconds] = None

            dct[k] = int(dct[k])
        return dct
    else:
        return None


def getVolumeInfo(target):
    ''' Returns a dict with information of the volume that lives in the backendSpec.
    @param target, specifies the backend and namespace
    @return, dict, a dict with information on the volume
    '''
    vol_info = ToolCut.VolumeInfo(target.params(), target.namespace())
    return {"volume_role": vol_info.role(),
            "volume_size": vol_info.size()}


class BackendTypeError(TypeError):
    pass


def verifyBackendWithNameSpaceType(backendnamespace):
    if not isinstance(backendnamespace, backend.BackendWithNamespace):
        raise TypeError("Expected %s got %s" %
                        (str(backend.BackendWithNamespace),
                         str(backendnamespace)))

    if backendnamespace.params()['backend_type'] not in ["REST", "LOCAL"]:
        raise BackendTypeError("Unsupported backend type: %s" %
                               backendnamespace.params()['backend_type'])


def getVolumeSnapshots(target, show_all=False):
    '''Returns a list of the snapshots in the backend.
        @param target, BackendWithNameSpace, specifies the backend
        @param show_all, boolean, also show snapshots that are not in the backend if True (default: False)
        @return, list, a list of snapshot names
    '''
    verifyBackendWithNameSpaceType(target)
    return [s.name() for s in ToolCut.SnapshotPersistor(target.params(), target.namespace()).getSnapshots() if show_all or s.inBackend()]


def getVolumeSnapshotsTool(target):
    '''Creates a ToolCut.SnapshotPersistor object on which further snapshot queries can be performed
           target, BackendWithNameSpace, specifies the backend
           returns ToolCut.SnapshotPersistor

       Example usage:

       snapshotsTool = getVolumeSnapshotsTool(target)
       for s in snapshotsTool.getSnapshots():
            print s.name()
            print s.stored()
            print s.date()
    '''
    verifyBackendWithNameSpaceType(target)
    return ToolCut.SnapshotPersistor(target.params(), target.namespace())


def maybeCreateDirs(cfg):
    drs = [cfg["target_configuration"]["volume_manager"]["tlog_path"],
           cfg["target_configuration"]["volume_manager"]["metadata_path"]] + \
        [mp["path"]
         for mp in cfg["target_configuration"]["scocache"]["scocache_mount_points"]]

    for d in drs:
        auxiliary.createDirSafe(d)


def createAdaptedConfig(tmpDir,
                        sourceCfg,
                        targetCfg,
                        startSnapshot=None,
                        endSnapshot=None):
    testConfiguration()

    if startSnapshot:
        sourceCfg["start_snapshot"] = startSnapshot

    if endSnapshot:
        sourceCfg["end_snapshot"] = endSnapshot

    targetCfg["volume_manager"] = {"tlog_path": os.path.join(tmpDir, "tlogs"),
                                   "metadata_path": os.path.join(tmpDir, "metadata")}

    targetCfg["scocache"] = {"scocache_mount_points":
                             [{"path": os.path.join(tmpDir, "scocache"), "size": "1GiB"}]}

    # keys with non-dict values already specified in cfg are kept
    cfg = getConfigTemplate()

    # bit hacky all this
    if sourceCfg != None:
        cfg = auxiliary.recursiveOverlayDict(
            {"source_configuration": sourceCfg},
            cfg)
    else:
        del cfg["source_configuration"]

    cfg = auxiliary.recursiveOverlayDict({"target_configuration": targetCfg},
                                         cfg)

    cfg["scratch_dir"] = os.path.join(tmpDir, "scratch")

    maybeCreateDirs(cfg)

    configFile = os.path.join(tmpDir, CONFIG_NAME)
    with open(configFile, "w") as fp:
        json.dump(cfg, fp, indent=4)
    return configFile


def prepareEnvironment(jobID,  # pylint: disable=W0613
                       workingDir,
                       sourceCfg,
                       targetCfg,
                       startSnapshot=None,
                       endSnapshot=None):
    configFile = createAdaptedConfig(workingDir,
                                     sourceCfg,
                                     targetCfg,
                                     startSnapshot,
                                     endSnapshot)

    return configFile


def runInEnvironment(workingDir, params, jobID):
    envir = os.environ.copy()
    args = params
    args += ["--configuration-file", os.path.join(workingDir, CONFIG_NAME)]
    args += ["--logfile", os.path.join(env.logDir, jobID + ".log")]

    with tempfile.SpooledTemporaryFile(max_size=1024) as errorout:
        try:
            subprocess.check_call(args,
                                  stderr=errorout,
                                  env=envir)
        except subprocess.CalledProcessError:
            errorout.seek(0)
            raise PointInTimeException(errorout.read())


def deleteSnapshots(target, snapshots):
    """Delete the snapshots on the backup target
       @param target: BackendWithNamespace
       @param snapshots: list of snapshots to delete
    """
    verifyBackendWithNameSpaceType(target)
    if snapshots != []:
        jobID = "deletesnapshots_job_" + str(uuid.uuid1())
        logger.info("Starting %s" % jobID)

        with auxiliary.cleanedUpDir(os.path.join(env.tmpDir,
                                                 jobID),
                                    cleanupOnException=True) as tmpDir:
            prepareEnvironment(jobID,
                               tmpDir,
                               {},
                               target.getJSONDict())
            runInEnvironment(tmpDir,
                             [BACKUP_BINARY] + [
                                 "--delete-snapshot=" + s for s in snapshots],
                             jobID)


def getScrubSnapshots(target):
    """Get scrubbing work from a backup target volume
        The target namespace must exist and have a valid volume for this to work.
    @param target : BackendWithNamespace
    """
    verifyBackendWithNameSpaceType(target)
    list_of_scrubbables = ToolCut.SnapshotPersistor(target.params(),
                                                    target.namespace()).getScrubbingWork()
    # the stuff returned from getWork in the volume interface looks differently
    # We can return that here by finishing getDict on BackendToolcut and passing
    # in more parameters... just return a list of the snapshots to be scrubbed
    # now
    return list_of_scrubbables


def backup(source, target, startSnapshot=None, endSnapshot=None):
    """ Creates a backup of the source volume to the target
        The target namespace must exist. If it already contains a backup volume, an incremental backup is applied.
        @param source : BackendWithNamespace
        @param target : BackendWithNamespace
    """
    verifyBackendWithNameSpaceType(target)
    jobID = "backup_job_" + str(uuid.uuid1())
    logger.info("Starting ID %s" % jobID)
    with auxiliary.cleanedUpDir(os.path.join(env.tmpDir,
                                             jobID),
                                cleanupOnException=True) as tmpDir:
        prepareEnvironment(jobID,
                           tmpDir,
                           source.getJSONDict(),
                           target.getJSONDict(),
                           startSnapshot,
                           endSnapshot)
        runInEnvironment(tmpDir, [BACKUP_BINARY], jobID)


def copy(source, target):
    """ Copies the backup in the source to the target
        @param source : BackendWithNamespace
        @param target : BackendWithNamespace
    """
    verifyBackendWithNameSpaceType(target)
    testConfiguration()
    jobID = "copy_job_" + str(uuid.uuid1())
    logger.info("Starting %s" % jobID)
    with auxiliary.cleanedUpDir(os.path.join(env.tmpDir,
                                             jobID),
                                cleanupOnException=True) as tmpDir:
        prepareEnvironment(jobID,
                           tmpDir,
                           source.getJSONDict(),
                           target.getJSONDict())

        runInEnvironment(tmpDir, [RESTORE_BINARY], jobID)


def _changeTarget(jobType, target, dictParams):
    verifyBackendWithNameSpaceType(target)
    testConfiguration()
    jobID = jobType + "_job_" + str(uuid.uuid1())
    logger.info("Starting %s" % jobID)
    with auxiliary.cleanedUpDir(os.path.join(env.tmpDir,
                                             jobID),
                                cleanupOnException=True) as tmpDir:
        targetCfg = auxiliary.recursiveOverlayDict(target.getJSONDict(),
                                                   dictParams)
        prepareEnvironment(jobID,
                           tmpDir,
                           None,
                           targetCfg)
        runInEnvironment(tmpDir, [RESTORE_BINARY], jobID)


def renameVolume(target, newVolumeName):
    """ Renames the volume on the specified target
        @param target : BackendWithNamespace
        @param newVolumeName : string
    """
    _changeTarget("rename", target, {"volume_name": newVolumeName})


def promote(target):
    """ Promotes a backup, necessary for restarting on the volumedriver
        @param target : BackendWithNamespace
    """
    _changeTarget("promote",
                  target,
                  {"volume_role": str(ToolCut.WanBackupVolumeRole.Normal)})

# def scrubSnapshot(target,
#                   snapshot,
#                   workdir = None,
#                   fill_ratio = 0.9,
#                   backend = 60):
#     verifyBackendWithNameSpaceType(target)
#     vol_inf = ToolCut.VolumeInfo(target.params() , target.namespace())
#     clustSize = vol_inf.clusterMultiplier() * vol_inf.lbaSize()

#     if clustSize != 2**12:
#         raise Exception("Cluster size other than 4k not supported")

# pylint: disable=W0212
#     workUnit = Scrubber._make_scrubbing_workunit(target,
#                                                  snapshot,
#                                                  12,
#                                                  vol_inf.scoMultiplier())
#     Scrubber.scrub(workUnit = workUnit,
#                    workdir = workdir,
#                    fill_ratio = fill_ratio,
#                    backend = dss_timeout,
#                    apply_immediately = True)

# AR: lift to the package's __init__ ?
__all__ = ["BackendTypeError",
           "backup",
           "copy",
           "deleteSnapshots",
           "getProgressInfo",
           "getScrubSnapshots",
           "getVolumeInfo",
           "getVolumeSnapshots",
           "getVolumeSnapshotsTool",
           "LOGGER_NAME",
           "prepareEnvironment",
           "promote",
           "renameVolume",
           "removeProgressInfo",
           "scrubSnapshot",
           "testConfiguration"]

# Local Variables: **
# mode : python **
# python-top-dir: "../../../../../../.." **
# End: **
